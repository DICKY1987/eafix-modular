# ALVT Layer 2+ Backlog
# doc_id: 0199900130260118

**Created:** 2026-01-23T19:09:00Z  
**Version:** 1.0  
**Status:** Planned - Not Yet Implemented  

## Overview

This document defines the backlog of verification layers beyond Layer 0 (Static Integrity) and Layer 1 (Graph Connectivity) that are intentionally deferred until the FILE_IDENTITY_CREATE pilot baseline is stable and frozen.

**Current Status:** Layer 0 + Layer 1 COMPLETE and FROZEN  
**Next Priority:** Layer 2 (Plan Determinism)

---

## Layer 2: Plan Determinism

### Purpose
Verify that automation execution plans are deterministic, reproducible, and hash-stable.

### Rationale
Even if wiring is complete (L0+L1), non-deterministic execution plans lead to:
- Unpredictable behavior
- Difficult debugging
- Inability to compare "before/after" plans
- Hidden race conditions

### What It Verifies
1. **Plan Generation Stability**
   - Same inputs → same plan (every time)
   - Plan hash is stable across multiple runs
   - Plan JSON serialization is deterministic (sorted keys, consistent formatting)

2. **Plan Structure Validity**
   - All steps have required fields (step_id, action, inputs, outputs)
   - No duplicate step_ids
   - Step execution order is explicit and deterministic
   - Dependencies between steps are declared

3. **Tool Availability**
   - All required tools/executors are available
   - Tool versions are pinned or documented
   - No missing dependencies

### Implementation Approach
- Extend ExecutionPlan class with `validate()` method
- Add `hash()` method for stable plan hashing
- Create `tools/alvt/layer2_plan.py` verifier
- Add `stable_dict()` for deterministic serialization
- Run plan generation 3 times, compare hashes

### Success Criteria
- [ ] Contract includes `execution_plan` section
- [ ] Plan generator exists and is callable
- [ ] Three consecutive plan generations produce identical hashes
- [ ] Plan validates without errors
- [ ] Report: `reports/alvt/plan.<trigger>.json` status=PASS

### Example Contract Section
```yaml
execution_plan:
  generator: "path/to/planner.py::generate_plan"
  required_tools: ["git", "python", "file_system"]
  plan_schema_version: "1.0"
```

---

## Layer 3: Sandbox Execution

### Purpose
Verify automation executes correctly end-to-end in an isolated test environment.

### Rationale
Static and graph verification prove wiring exists but not that it **works**. Layer 3 proves:
- Automation runs to completion
- Expected artifacts are created
- Evidence is recorded
- Side effects are contained

### What It Verifies
1. **Workspace Isolation**
   - All file operations occur within workspace
   - No writes to global state
   - Registry operations use workspace-relative paths
   - Cleanup leaves no artifacts outside workspace

2. **End-to-End Execution**
   - Trigger event → execution → completion
   - All gates pass
   - All expected outputs created
   - Evidence recorded correctly

3. **Artifact Validation**
   - Output files exist at expected paths
   - Output content matches expected schema/format
   - File permissions are correct
   - Timestamps are reasonable

### Implementation Approach
- Extend automation pattern with Workspace concept
- Create FakeOps and RealOps injectors
- Add `tools/alvt/layer3_sandbox.py` executor
- Use pytest fixtures for workspace setup/teardown
- Compare actual vs. expected artifacts

### Success Criteria
- [ ] Contract includes `expected_outputs` section
- [ ] Sandbox workspace created (tmp_path)
- [ ] Trigger executes without errors
- [ ] All expected files created
- [ ] All evidence recorded
- [ ] Workspace cleanup successful
- [ ] Report: `reports/alvt/sandbox.<trigger>.json` status=PASS

### Example Contract Section
```yaml
expected_outputs:
  - artifact_id: "renamed_file"
    path: "workspace/{original_filename}"
    type: "file"
    validation: "exists"
  - artifact_id: "execution_log"
    path: "workspace/.evidence/execution.log"
    type: "evidence"
    validation: "contains:execution_completed"
```

---

## Layer 4: Negative Path Validation

### Purpose
Verify automation handles errors, failures, and edge cases gracefully.

### Rationale
Happy-path testing (Layer 3) is insufficient. Layer 4 ensures:
- Errors are detected and reported
- Rollback works correctly
- System remains in valid state after failure
- No partial/corrupt artifacts left behind

### What It Verifies
1. **Error Detection**
   - Missing input files detected
   - Invalid inputs rejected
   - Gate failures cause execution halt
   - Errors logged with context

2. **Rollback Correctness**
   - Failed execution triggers rollback
   - Rollback restores original state
   - No orphaned artifacts after rollback
   - Idempotency preserved

3. **Edge Case Handling**
   - Empty inputs handled
   - Duplicate triggers handled (idempotency)
   - Concurrent execution conflicts detected
   - Resource exhaustion handled

### Implementation Approach
- Add `rollback` section to contract
- Create test scenarios for each failure mode
- Add `tools/alvt/layer4_negative.py` tester
- Force gate failures, missing files, invalid inputs
- Verify rollback cleanup

### Success Criteria
- [ ] Contract includes `failure_modes` section
- [ ] Rollback handler exists
- [ ] At least 3 negative scenarios tested:
  - Missing input file
  - Gate failure
  - Mid-execution error
- [ ] Rollback restores original state in all cases
- [ ] No orphaned artifacts after rollback
- [ ] Report: `reports/alvt/negative.<trigger>.json` status=PASS

### Example Contract Section
```yaml
failure_modes:
  - scenario: "missing_input_file"
    trigger_inputs: {"file_path": "nonexistent.txt"}
    expected_error: "FileNotFoundError"
    rollback_expected: true
  
  - scenario: "gate_failure"
    gate_to_fail: "has_prefix_check"
    expected_error: "GateFailure"
    rollback_expected: true

rollback:
  handler: "path/to/handler.py::rollback_function"
  verification: "original_state_restored"
```

---

## Layer 5: Idempotency Verification

### Purpose
Verify automation can safely re-execute with same inputs without corruption.

### Rationale
Automation may need to re-run due to:
- Transient failures
- Retries in CI/CD
- Manual re-execution
Layer 5 ensures re-execution is safe.

### What It Verifies
1. **Safe Re-execution**
   - Second run detects prior execution
   - No duplicate artifacts created
   - State remains consistent
   - Evidence updated (not duplicated)

2. **Idempotency Policy Compliance**
   - `run-once`: Second run is no-op or error
   - `safe-rerun`: Second run updates state correctly
   - `conditional`: Second run checks preconditions first

3. **Evidence Consistency**
   - Re-run evidence appends (doesn't replace)
   - Run IDs are unique
   - Correlation IDs link related runs

### Implementation Approach
- Add `idempotency` section to contract
- Create `tools/alvt/layer5_idempotency.py` tester
- Run trigger twice with identical inputs
- Compare before/after state
- Verify policy compliance

### Success Criteria
- [ ] Contract includes `idempotency.policy`
- [ ] First execution completes successfully
- [ ] Second execution with same inputs behaves according to policy:
  - `run-once`: Returns "already executed" or similar
  - `safe-rerun`: Completes successfully, state consistent
  - `conditional`: Checks condition, executes only if needed
- [ ] No corruption or duplicate artifacts
- [ ] Report: `reports/alvt/idempotency.<trigger>.json` status=PASS

### Example Contract Section
```yaml
idempotency:
  policy: "safe-rerun"  # One of: run-once, safe-rerun, conditional
  detection_method: "has_prefix_check"  # How automation detects prior execution
  expected_behavior: "skip_if_exists"  # What happens on re-run
```

---

## Layer 6: Performance Validation (Future)

### Purpose
Verify automation meets performance requirements (execution time, resource usage).

### What It Verifies
- Execution completes within timeout
- Memory usage within limits
- No resource leaks
- Scales appropriately with input size

### Deferred Reason
Performance optimization premature before correctness proven.

---

## Layer 7: Security Validation (Future)

### Purpose
Verify automation respects security boundaries and policies.

### What It Verifies
- No unauthorized file access
- No secret leakage in logs/evidence
- Privilege escalation prevented
- Input sanitization correct

### Deferred Reason
Security layer requires threat model definition first.

---

## Implementation Priority

### Phase 1: Layer 2 (Plan Determinism)
**Priority:** HIGH  
**Reason:** Cheapest to implement, high value (detects many bugs early)  
**Effort:** Small (extend existing ExecutionPlan pattern)  
**Dependencies:** None (can implement immediately)

### Phase 2: Layer 3 (Sandbox Execution)
**Priority:** HIGH  
**Reason:** Proves automation actually works, not just wired correctly  
**Effort:** Medium (requires workspace abstraction, ops injection pattern already exists)  
**Dependencies:** Layer 2 (need stable plans to execute)

### Phase 3: Layer 4 (Negative Paths)
**Priority:** MEDIUM  
**Reason:** Critical for production resilience  
**Effort:** Medium (requires rollback handlers, failure injection)  
**Dependencies:** Layer 3 (need working execution before testing failures)

### Phase 4: Layer 5 (Idempotency)
**Priority:** MEDIUM  
**Reason:** Important for retry logic, CI/CD integration  
**Effort:** Small (extends Layer 3 with repeat execution)  
**Dependencies:** Layer 3 (need working execution)

### Phase 5: Layers 6-7 (Performance, Security)
**Priority:** LOW (for now)  
**Reason:** Important but not blocking for basic automation verification  
**Effort:** Large (requires specialized tooling)  
**Dependencies:** Layers 2-5 complete

---

## Recommended Next Steps

### Immediate (Post-Pilot)
1. ✅ Freeze FILE_IDENTITY_CREATE baseline (Phase 6 complete)
2. ⏭️ Add one more trigger using checklist (prove scalability)
3. ⏭️ Implement Layer 2 for FILE_IDENTITY_CREATE
4. ⏭️ Run Layer 2 against all triggers

### Short-Term (Next Sprint)
1. Implement Layer 3 sandbox execution framework
2. Add Layer 3 tests for FILE_IDENTITY_CREATE
3. Document workspace isolation patterns
4. Integrate Layer 2+3 into CI/CD pipeline

### Medium-Term (Next Month)
1. Implement Layer 4 negative path testing
2. Define rollback contracts for all triggers
3. Add Layer 5 idempotency verification
4. Create bulk verification script (all triggers, all layers)

### Long-Term (Next Quarter)
1. Evaluate Layer 6 performance requirements
2. Define security threat model for Layer 7
3. Consider automation-as-code governance (policy enforcement)
4. Explore self-healing automation (auto-fix based on ALVT failures)

---

## Success Metrics (Layer 2+)

### Quality Gates
- All triggers pass Layer 2 (plan determinism)
- At least 1 trigger passes Layer 3 (sandbox execution)
- At least 1 trigger passes Layer 4 (negative paths)
- At least 1 trigger passes Layer 5 (idempotency)

### Adoption Metrics
- % of triggers with Layer 2 verification: Target 100%
- % of triggers with Layer 3 verification: Target 80%
- % of triggers with Layer 4 verification: Target 50%
- % of triggers with Layer 5 verification: Target 50%

### Integration Metrics
- ALVT verification integrated into CI/CD: Target YES
- Pre-commit hooks run ALVT Layer 0+1: Target YES
- Automated ALVT report generation: Target YES

---

## References

- Pilot Baseline: `contracts/triggers/0199900129260118_pilot_baseline_locked.md`
- Architecture: `contracts/triggers/0199900116260118_automation_verification_architecture.md`
- Automation Pattern: `Directory management system/automation minimal production-pattern.md`
- Phase Plan: `Directory management system/autoplan.txt`

---

**Backlog Status:** DEFINED  
**Implementation Status:** PENDING (Layer 0+1 complete, Layer 2+ awaiting prioritization)  
**Owner:** ALVT maintainers  
**Review Cycle:** After each new trigger added, reassess Layer 2+ priority
